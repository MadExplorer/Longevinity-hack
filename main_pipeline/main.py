# -*- coding: utf-8 -*-
"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –¥–æ–ª–≥–æ–ª–µ—Ç–∏—è
–ü—Ä–æ—Å—Ç–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
"""

from pathlib import Path
from datetime import datetime
import os

from graph import ScientificKnowledgeGraph
from analysis import ResearchAnalyst
from processing import load_documents

def create_results_folder():
    """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    # –ë–∞–∑–æ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    base_results_dir = Path("results")
    
    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    base_results_dir.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É —Å –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    analysis_dir = base_results_dir / f"analysis_{timestamp}"
    analysis_dir.mkdir(exist_ok=True)
    
    print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {analysis_dir}")
    return analysis_dir

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_dir = create_results_folder()
    
    # –§–∞–π–ª—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤ –ø–∞–ø–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    GRAPH_FILE = results_dir / "longevity_knowledge_graph.graphml"
    REPORT_FILE = results_dir / "research_report.json"
    HIERARCHICAL_REPORT_FILE = results_dir / "hierarchical_research_report.json"
    ENTITY_MAP_FILE = results_dir / "entity_normalization_map.json"
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    FORCE_REBUILD = True  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ True –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∞
    MAX_WORKERS = 30  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    # –ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º - –ò–ó–ú–ï–ù–ò–¢–ï –ó–î–ï–°–¨ –¥–ª—è –¥—Ä—É–≥–æ–π –ø–∞–ø–∫–∏
    PDF_FOLDER = "downloaded_pdfs/references_dlya_statiy_2025"
    USE_CACHE = True  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ False –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞–Ω–∏—è PDF —Ñ–∞–π–ª–æ–≤
    
    print("üß¨ --- LONGEVITY RESEARCH GRAPH ANALYZER ---")
    print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_dir}")
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π
    skg = ScientificKnowledgeGraph()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥—Ä–∞—Ñ
    # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: —Ç–µ–ø–µ—Ä—å –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –≥—Ä–∞—Ñ, –Ω–æ –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É
    graph_exists = GRAPH_FILE.exists()
    
    if graph_exists and not FORCE_REBUILD:
        print(f"üìÅ –ù–∞–π–¥–µ–Ω —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –≥—Ä–∞—Ñ: {GRAPH_FILE}")
        if skg.load_graph(str(GRAPH_FILE)):
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞
            stats = skg.get_graph_stats()
            print(f"   üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥—Ä–∞—Ñ–∞:")
            print(f"      ‚Ä¢ –°—Ç–∞—Ç—å–∏: {stats['papers']}")
            print(f"      ‚Ä¢ –ì–∏–ø–æ—Ç–µ–∑—ã: {stats['hypotheses']}")
            print(f"      ‚Ä¢ –ú–µ—Ç–æ–¥—ã: {stats['methods']}")
            print(f"      ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {stats['results']}")
            print(f"      ‚Ä¢ –ó–∞–∫–ª—é—á–µ–Ω–∏—è: {stats['conclusions']}")
            print(f"      ‚Ä¢ –°—É—â–Ω–æ—Å—Ç–∏: {stats['entities']}")
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä–∞—Ñ–∞. –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å –Ω—É–ª—è.")
            graph_exists = False
    
    # –ï—Å–ª–∏ –≥—Ä–∞—Ñ–∞ –Ω–µ—Ç –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - —Å—Ç—Ä–æ–∏–º –Ω–æ–≤—ã–π
    if not graph_exists or FORCE_REBUILD:
        if FORCE_REBUILD:
            print("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∞...")
        else:
            print("üìÅ –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –≥—Ä–∞—Ñ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞—é –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å –Ω—É–ª—è.")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏
        print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ø–∞–ø–∫–∏: {PDF_FOLDER}")
        documents = load_documents(data_source=PDF_FOLDER, use_cache=USE_CACHE, max_workers=MAX_WORKERS)
        
        if not documents:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
            return
        
        print("üß¨ --- Stage 1: Building the Knowledge Graph ---")
        skg.build_graph(documents, max_workers=MAX_WORKERS, force_rebuild_normalization=FORCE_REBUILD)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ
        if skg.save_graph(str(GRAPH_FILE)):
            stats = skg.get_graph_stats()
            print(f"‚úÖ –ì—Ä–∞—Ñ –ø–æ—Å—Ç—Ä–æ–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {stats['nodes']} —É–∑–ª–æ–≤, {stats['edges']} —Ä—ë–±–µ—Ä")
        else:
            print("‚ö†Ô∏è –ì—Ä–∞—Ñ –ø–æ—Å—Ç—Ä–æ–µ–Ω, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –ø–∞–ø–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        import shutil
        source_entity_map = "entity_normalization_map.json"
        if Path(source_entity_map).exists():
            try:
                shutil.copy2(source_entity_map, str(ENTITY_MAP_FILE))
                print(f"‚úÖ –ö–∞—Ä—Ç–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –≤: {ENTITY_MAP_FILE}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—Ä—Ç—ã —Å—É—â–Ω–æ—Å—Ç–µ–π: {e}")
        else:
            print("‚ö†Ô∏è –§–∞–π–ª –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    print("\nüî¨ --- Stage 2: Analysis and Prioritization ---")
    analyst = ResearchAnalyst(skg)

    print("\n   üåü -> Divergent Phase: Generating raw research directions...")
    raw_directions = analyst.generate_research_directions(max_workers=MAX_WORKERS)
    print(f"   ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(raw_directions)} –∏—Å—Ö–æ–¥–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π.")
    
    if raw_directions:
        # –ù–æ–≤—ã–π –≤—ã–∑–æ–≤ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ v2.0
        hierarchical_report = analyst.analyze_and_synthesize_report(raw_directions, max_workers=MAX_WORKERS)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç
        if analyst.save_hierarchical_report(hierarchical_report, str(HIERARCHICAL_REPORT_FILE)):
            print(f"‚úÖ –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {HIERARCHICAL_REPORT_FILE}")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—ã)
        if hierarchical_report.programs:
            all_directions = []
            for program in hierarchical_report.programs:
                all_directions.extend(program.component_directions)
            all_directions.extend(hierarchical_report.unclustered_directions)
            
            if analyst.save_report(all_directions, str(REPORT_FILE)):
                print(f"‚úÖ –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {REPORT_FILE}")

        # –í—ã–≤–æ–¥–∏–º –Ω–æ–≤—ã–π —Å–∞–º–º–∞—Ä–∏
        print("\nüèÜ --- FINAL HIERARCHICAL REPORT SUMMARY ---")
        print(f"   üìà –í—Å–µ–≥–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º: {hierarchical_report.total_programs}")
        print(f"   üìà –ù–µ—Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(hierarchical_report.unclustered_directions)}")
        
        for i, program in enumerate(hierarchical_report.programs):
            print(f"\n   üìã –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê #{i+1}: {program.program_title}")
            print(f"      üìù –û–ø–∏—Å–∞–Ω–∏–µ: {program.program_summary}")
            print(f"      üîó –í–∫–ª—é—á–∞–µ—Ç –∏–¥–µ–π: {len(program.component_directions)}")
            print(f"      üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ {len(program.subgroups)} –ø–æ–¥–≥—Ä—É–ø–ø:")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ–¥–≥—Ä—É–ø–ø
            for j, subgroup in enumerate(program.subgroups):
                print(f"         {j+1}. {subgroup.subgroup_type} ({len(subgroup.directions)} –∏–¥–µ–π)")
                print(f"            {subgroup.subgroup_description}")
                
                # –õ—É—á—à–∞—è –∏–¥–µ—è –≤ –ø–æ–¥–≥—Ä—É–ø–ø–µ
                if subgroup.directions:
                    best_in_subgroup = min(subgroup.directions, key=lambda d: d.rank)
                    print(f"            üèÜ –¢–æ–ø: {best_in_subgroup.title[:60]}... (—Å–∫–æ—Ä: {best_in_subgroup.critique.final_score:.2f})")
            
            # –û–±—â–∞—è –ª—É—á—à–∞—è –∏–¥–µ—è –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ
            if program.component_directions:
                best_overall = min(program.component_directions, key=lambda d: d.rank)
                print(f"      ü•á –û–±—â–∏–π —Ç–æ–ø –ø—Ä–æ–≥—Ä–∞–º–º—ã: {best_overall.title} (—Å–∫–æ—Ä: {best_overall.critique.final_score:.2f})")
        
        print(f"\n   üîç –ü–æ–ª–Ω—ã–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å–º. –≤ —Ñ–∞–π–ª–µ: {HIERARCHICAL_REPORT_FILE}")
    else:
        print("   ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {results_dir}")
    print(f"   ‚Ä¢ –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π: {GRAPH_FILE.name}")
    print(f"   ‚Ä¢ –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç v2.0: {HIERARCHICAL_REPORT_FILE.name}")
    print(f"   ‚Ä¢ –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞: {REPORT_FILE.name}")
    print(f"   ‚Ä¢ –ö–∞—Ä—Ç–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π: {ENTITY_MAP_FILE.name}")
    print("üîÑ –î–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ FORCE_REBUILD = True")

if __name__ == '__main__':
    main() 