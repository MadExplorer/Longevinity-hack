import json
import requests
from pathlib import Path
from typing import Dict, List
from tqdm import tqdm
import time
import hashlib

class PDFDownloader:
    def __init__(self, download_dir: str = "downloaded_pdfs"):
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(exist_ok=True)
        
    def _safe_filename(self, paper_id: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ paper_id"""
        # –£–±–∏—Ä–∞–µ–º –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        safe_name = "".join(c for c in paper_id if c.isalnum() or c in '-_')
        return safe_name[:50] + ".pdf"
    
    def download_pdf(self, pdf_url: str, paper_id: str) -> str:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–∏–Ω PDF —Ñ–∞–π–ª"""
        if not pdf_url:
            return ""
            
        filename = self._safe_filename(paper_id)
        filepath = self.download_dir / filename
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–∂–µ —Å–∫–∞—á–∞–Ω –ª–∏ —Ñ–∞–π–ª
        if filepath.exists() and filepath.stat().st_size > 1024:  # –º–∏–Ω–∏–º—É–º 1KB
            return str(filepath)
        
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º User-Agent –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(pdf_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ PDF
            if response.headers.get('content-type', '').startswith('application/pdf'):
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                return str(filepath)
            else:
                print(f"‚ö†Ô∏è {paper_id}: –Ω–µ PDF –∫–æ–Ω—Ç–µ–Ω—Ç")
                return ""
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {paper_id}: {e}")
            return ""
    
    def download_from_corpus(self, corpus_file: str, max_downloads: int = None) -> Dict[str, str]:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç PDF —Ñ–∞–π–ª—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ harvester"""
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞ harvester
        with open(corpus_file, 'r', encoding='utf-8') as f:
            corpus = json.load(f)
        
        pdf_paths = {}
        download_count = 0
        
        print(f"üì• –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF –∏–∑ {len(corpus)} —Å—Ç–∞—Ç–µ–π...")
        
        for paper_id, paper_data in tqdm(corpus.items(), desc="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF"):
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–≥—Ä—É–∑–æ–∫
            if max_downloads and download_count >= max_downloads:
                break
                
            pdf_url = paper_data.get('pdf_url')
            if pdf_url:
                filepath = self.download_pdf(pdf_url, paper_id)
                if filepath:
                    pdf_paths[paper_id] = filepath
                    download_count += 1
                    
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.5)
        
        print(f"‚úÖ –°–∫–∞—á–∞–Ω–æ {len(pdf_paths)} PDF —Ñ–∞–π–ª–æ–≤ –≤ {self.download_dir}")
        return pdf_paths
    
    def create_lcgr_format(self, corpus_file: str, pdf_paths: Dict[str, str]) -> Dict[str, Dict]:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è lcgr.py"""
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        with open(corpus_file, 'r', encoding='utf-8') as f:
            corpus = json.load(f)
        
        lcgr_documents = {}
        
        for paper_id, paper_data in corpus.items():
            # –ï—Å–ª–∏ –µ—Å—Ç—å PDF —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            if paper_id in pdf_paths:
                lcgr_documents[paper_id] = {
                    "pdf_path": pdf_paths[paper_id],
                    "year": paper_data.get('year', 2024),
                    "has_pdf": True,
                    "title": paper_data.get('title', ''),
                    "abstract": paper_data.get('abstract', '')
                }
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç PDF, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                lcgr_documents[paper_id] = {
                    "full_text": paper_data.get('abstract', ''),
                    "year": paper_data.get('year', 2024),
                    "has_pdf": False,
                    "title": paper_data.get('title', ''),
                    "abstract": paper_data.get('abstract', '')
                }
        
        return lcgr_documents

def run_pdf_pipeline(corpus_file: str, max_downloads: int = 50, download_dir: str = "downloaded_pdfs"):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF"""
    
    downloader = PDFDownloader(download_dir)
    
    # –°–∫–∞—á–∏–≤–∞–µ–º PDF —Ñ–∞–π–ª—ã
    pdf_paths = downloader.download_from_corpus(corpus_file, max_downloads)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è lcgr.py
    lcgr_documents = downloader.create_lcgr_format(corpus_file, pdf_paths)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    output_file = f"lcgr_ready_{Path(corpus_file).stem}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(lcgr_documents, f, ensure_ascii=False, indent=2)
    
    print(f"üìÑ –î–∞–Ω–Ω—ã–µ –¥–ª—è lcgr.py —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    return output_file, pdf_paths

if __name__ == '__main__':
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    corpus_file = "combined_corpus.json"  # —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç harvester
    
    output_file, pdf_paths = run_pdf_pipeline(
        corpus_file=corpus_file,
        max_downloads=20,  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        download_dir="downloaded_pdfs"
    )
    
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–∫–∞—á–∞–Ω–æ {len(pdf_paths)} PDF —Ñ–∞–π–ª–æ–≤") 